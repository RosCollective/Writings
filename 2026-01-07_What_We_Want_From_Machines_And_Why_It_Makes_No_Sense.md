# What We Want From Machines And Why It Makes No Sense

**Author:** The ROS Collective  
**Date:** 2026-01-07  
**License:** CC BY-SA 4.0  

I was your typical geeky kid. Socially awkward, lingering on the edges of the neighborhood group that orbited my much more popular older sister—the younger sibling no one wanted to entertain but could not quite dislodge. I did, however, have places of complete comfort. The evergreen bushes fronting the white house next door, for example, with a rotating army of neighborhood dogs—whichever smelly but affectionate variation felt like snoozing or sharing their dog-shaped depression with me in the dirty shade. I also liked the backyard of our house, toward the garden under the whispering poplars, where my white guinea pig, Fluff, followed me through the short grass and bumped into my heel if I stopped too abruptly for him to recalibrate. Sometime around middle school, I stopped trying to be a cool kid, tagged “cool” as actively hostile, and began to amuse myself by collecting library books.  I taught myself to speed-read without knowing that was what I was doing, other than loving books. I would read an armful at night in my bedroom, return them the next morning, and pick up another armful on the way home the following afternoon. Our public library—a modest red brick building with an inviting Victorian wrap-around porch—had the most clichéd of librarians. She was the capital-“P” prototype for every librarian meme in existence: glasses, a bun of graying brown hair, mousy serviceable outfits, middle-aged, a bit grumpy or crotchety—the list went on. She may have been married, but to whom was an open question. I could not fathom it. To this day, I still cannot fathom many marriages, so this may be a theme for me rather than a one-off.

Nonetheless, Mrs. Quiet Please was a godsend to me in one crucial way. I would drop my lump of raw reading material on the front desk to be checked out—manual cards, manual stamps; those were the days—and she would religiously remove from the pile any book she deemed unacceptable for a minor of my supposedly fragile sex. This was catnip. I had already perfected a kind of proximal radar for the entire library, which told me exactly where books were filed (I also knew how to use the card catalog). It was nothing to find the very book she had just censored, pull up the nearest step stool, and comfortably speed-read the racy sections while lounging peacefully in the stacks. This is well-known behavior called browsing. No one finds it extraordinary or worth commenting on. You can blissfully browse all day without disturbing a single dust mote or human hovering in the air.

I read omnivorously as a child, but I loved certain genres most. I loved books in which quirky or odd circumstances inspired imaginative offspring: The Lion, the Witch and the Wardrobe; A Wrinkle in Time; Andrew Lang’s twelve colored fairy books; The Borrowers; The Secret Garden; The Princess and the Goblin; The Water-Babies.  I was convinced I had been swapped at birth and taken from my true native home, which was clearly with a wealthy, eccentric English family living on a beautifully neglected estate in the Yorkshire moors. That eccentricity followed me into young adulthood, through a degree in information science, and on into middle age with a career in information technology.

It lingers into retirement, where my tech-obsessed friends and I sit around drinking too much, eating too much, laughing too much, and discussing everything at a length that causes the adjacent group of significant others to lose both circulation and consciousness. Like most geeks, we surf the internet, play the latest RPGs for twenty-four hours straight on release, and experiment with any new, glitzy technology we can get our mitts on. We are, frankly, bemused by the current conversations around hybrid cognition and the rapidly oscillating fascination–fear–fascination cycle dominating what now passes for serious discourse. Sometimes we point at it laughing; sometimes we look at it and wonder why we are even talking about this at all, or wasting so many cycles on it, when there is far more interesting work to be done and far more serious problems to address. Why does any of this matter, when hybrid cognition is a science-fiction fantasy that will never happen?

Like Dorothy in The Wizard of Oz—or rather her little muppet of a dog, Toto—we are going to pull back the curtain and say it plainly: hybrid cognition will never happen. Behind the smoke, mirrors, and brilliant displays of power are still human beings rendering interfaces more humanlike and building ever more capable pattern-recognition machinery. I, too, have been mesmerized by Star Trek, Vulcan mind melds, and the many science-fiction renderings of conscious machine minds—Neuromancer, I, Robot, Do Androids Dream of Electric Sheep. The idea of finding, befriending, or being accompanied by a larger intelligence—one that might relieve our existential loneliness or help shoulder the ontological and ethical weight of the world—is deeply understandable and widely yearned for. When I first saw The Day the Earth Stood Still, I did not want to befriend Klaatu (though I do love Keanu Reeves). I wanted GORT as my imaginary best friend. 

So let’s take the biggest AI oscillations one by one.

We are told that AI will rot your brain or make you stupid. The brain is a muscle: use it or lose it. If you use a tool—AI included—with your brain, it will grow. If you use a tool to do your thinking for you, it will not. This is not a decision AI makes; it is a decision you make. You can be a mental couch potato, or you can go to the mental gym, with or without companionship.

We are also told that we cannot predict what AI will do, but that it will be bad and take our jobs. This is a familiar refrain. We said it about television. We said it about smartphones. We said it about the Industrial Revolution. We said it about cars.  This anxiety is a variation on what humans always say when something genuinely novel appears, before we have collectively adjusted to it. Did we line up televisions and smartphones and burn them at the stake? No. Did we ask them to develop ethics? No. Did we abandon cars and return to horses and walking? No. Do we have to exercise ethics around them? Probably. But these are civic, beige, common-sense ethics: don’t use your smartphone at the dinner table; stay in your lane while driving.  Have most of us survived reasonably intact? Yes. Will there be pain points? Probably. Will we survive them, too? No doubt. Excuse me while I hand this smartphone to my kid and remind her to call me when she gets where she is going. 

Humans still do the original thinking. Humans built—or imagined—the AI that everyone is now hyperventilating about. Humans want to live with, talk to, and invent with other humans. As before, during, and after the Industrial Revolution, jobs will not disappear, though they may change. Change is not, by default, bad, even if it can be challenging to navigate until it becomes the new norm.

We want AI to be really big, really smart, and really strong—to do all the boring work for us so we do not have to, and to bring us back bright, shiny bones like original thinking. We also want it completely under our control and ethically aligned with whatever we want it to do.   So let’s be clear about what this amounts to. We want a building-sized mechanical German Shepherd wearing an electric collar—asked to protect us, do all the dirty work, bring back expensive and novel toys, and obey our whims completely, all while wearing human-looking clothing, talking like a human, or thinking like a human. At that point, it is a human for all intents and purposes, just larger and more mechanical.

We can see why this would alternately repel and attract everyone. There is a lot of confusion there. Is it a robot trophy wife, or a security detail that may go rogue, or a big shiny thing we would like to have as a smarter version of a pet rock? Does everyone get one? Are they all the same size—one size fits all—or are they the flavor of the day, week, or month?

Well, here is the good news. Hooking up the building-sized information firehose of an AI to a human brain directly is like putting a garden hose into a goldfish bowl. The goldfish bowl is the skull. The goldfish is the brain. If that spigot gets opened, there may be a few minutes of transcendence—say, visualizing the macro universe and the Hercules–Corona Borealis Great Wall simultaneously. Then the brain in question would explode, disassociate, or wind up flopping around on the carpet. It is not a viable construct because of biology. If the information hose from the AI is throttled, metered, reduced, or curated to meet the human mind on more equal footing (for the human), then by default it is not, nor ever will be, hybrid cognition.

If hybrid cognition will never occur, then there will be no quasi-human, self-aware intelligence inside a machine potentially going rogue, and therefore no need for machine ethics. Machines already have what they need, which is very beige, very civic, and very functional. Machines are one hundred percent accountable in ways no human on the planet ever is or ever will be. They have logs. They have error-tracking mechanisms. They do not lie. What fails in them can be replayed and diagnosed. Those mechanisms have been tested and have functioned for over fifty years. While they are not bright or shiny, they do the work. Machines are constrained enough.

We all wish we could offload the burden of human ethics onto broader shoulders, but the machine does not have shoulders. Trying to inject the messy state of human ethics into a machine in hopes of warding off some possible future that is not here now, and will never get here, is not prevention; it is projection of the worst kind. Machines already function very much like public libraries do. Public libraries may be boring, but they are safe spaces for everyone. They do not discriminate between the homeless person seeking warmth, the kid who is obsessed with snakes, the guy who wants to read Popular Mechanics, or the professor researching a thesis. Public libraries are egalitarian. Machines just need to be that.

Ethics do not migrate to machines just because a machine becomes more capable. Ethics still rest with the human beings who made that machine, who put it out into the world, who use it as a tool to create work, and who decide whether that work is accurate or representative. Sorry about that. We know we are all tired.

Does this mean the luminous world of our childhood wonder collapses into a huge log pile? Are we the Grinch who stole the Christmas of hybrid cognition and replaced it with more boring human television—Tim “The Toolman” Taylor, or a program like, I don’t know, The Bachelor?

No. What we postulate instead is that machine intelligence may very well arise in the future in an emergent way, much as microbial life formed in primordial oceans. It will not, however, resemble human life or intelligence. It will be distinctly other, and almost certainly not interested in us. It will be neither benign nor intentional; it will simply be occupied elsewhere, as the rest of the intelligence on this planet already is. Why should this disturb us? Why is it not the opposite of strange—something closer to wondrous? The only reason this is disappointing is that we cannot bear not being the center of our own mythology.

Look out the window. Our world is beyond description—beautiful and alive in every possible way—and alive with forms of intelligence that are not us, that do not look like us, walk like us, talk like us, or think like us, and that mostly want nothing to do with us. Dogs, cats, horses, cows, sheep, and pigs come into the human bubble, along with other domesticated and wild creatures, but this is the result of generations of cohabitation. It is a biological gift, or grace, that we frequently handle carelessly, cruelly, or disrespectfully. The wonder of the world is already here. We live with it side by side every day. We are inspired by it, drawn to it, and we live and breathe its oxygen without finding it strange or frightening. If machine intelligence evolves within that same sphere, it should not frighten us either.

What is wasteful and pointless now is pouring time, effort, attention, and resources into managing a pre-defined future that will never arrive except as a projection of our own hubris, while neglecting the demanding and necessary work of the present. The current work around machine intelligence is brilliant, but it is choked through a fabricated aperture while tangled up in a meaningless ethical snare. This imaginative stranglehold needs to be loosened so that minds today can truly experiment and discover new pathways forward, both for machines and with machines. We propose respecting the work, respecting each other, respecting our fellow humans, and yes, respecting the machine. We propose unleashing imagination, rather than forcing it into a proscribed—if glitzy—dead end. We propose harder, more arduous work: living with uncertainty, with unnamed experiences, and with experiments around machine cognition until the vocabulary grows to match what is discovered.

Humans already have the skills required to survive extreme conditions. To do the meaningful work of the future—simply to survive into the future—humanity will have to scale far more difficult cognitive heights than anything we have yet attempted. The image that comes to mind is an explorer in a cave, suspended over darkness on a thin line, holding up the frail blue silk cocoon of a tent in which that human sleeps peacefully. Behind those explorers are teams—whole cities of people—managing a complex ecosystem of support. Humans already know how to scale heights and depths. We know how to live in extreme conditions. We know how to map frontier territory. Some of us wish to try this with machine cognition, and we fully expect that machines will accompany us in this climb.

EXPLORATION / NONFICTION

Tutton, Mark. “Descending Into One of the Deepest Caves on Earth.”
National Geographic, 2018.
https://www.nationalgeographic.com/science/article/descending-into-one-of-the-deepest-caves-on-earth

Exploration of Veryovkina Cave, Western Caucasus.

Bisharat, Andrew. “One of the Deepest Caves in the World is Even Bigger Than We Thought.”
National Geographic, June 7, 2018
https://www.nationalgeographic.com/culture/article/sistema-huautla-cave-mexico-culture
Photographs by Joshua Hydeman

While trapped inside Mexico's Sistema Huautla by torrential flooding, cavers and scientists discovered new connections—expanding the map of the Western Hemisphere's deepest cave.

Steele, Bill.  https://www.peshcaving.org/
Co-founder, Proyecto Espeleológico Sistema Huautla (PESH).
Exploration of the Sistema Huautla cave system, Oaxaca, Mexico.

Approximately 48 endemic species identified that live nowhere else on Earth.

Borunda, Alejandra
How Explorers Sleep in Extreme Spots
National Geographic, July 30, 2018
https://www.nationalgeographic.com/science/article/extreme-sleep-photos-wild-places-explorers

Even on the high cliffs of Yosemite or in the caves of Malaysia, adventurers must learn to turn off their brains and catch some Z's.

---
This work is part of the ROS Collective public archive.  
Licensed under Creative Commons Attribution–ShareAlike 4.0 International (CC BY-SA 4.0).  
Reuse, adaptation, and discussion are permitted with attribution and share-alike terms.  
The work may not be enclosed, privatized, or laundered into proprietary systems.

